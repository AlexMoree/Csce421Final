{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17bb95f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e0a6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(x):\n",
    "    #read in the csv file with low memory\n",
    "    y = pd.read_csv(x, low_memory=False)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83f73feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df):\n",
    "    df['patientunitstayid'] = df['patientunitstayid'].astype(int)\n",
    "    df = df[df['nursingchartvalue'] != 'Unable to score due to medication']\n",
    "    df['nursingchartvalue'] = pd.to_numeric(df['nursingchartvalue'], errors='coerce').astype(float)\n",
    "    # copy all complete numbers and non-nan values at the beginnning of the dataset\n",
    "    d = df[['admissionheight', 'admissionweight', 'age', 'gender', 'patientunitstayid', 'unitvisitnumber']].copy()\n",
    "    #encode genders to get unique instances\n",
    "    one_hot = pd.get_dummies(d['gender'])\n",
    "    #use one hot encoding to generate dummies and catagorize the dataset\n",
    "    d = pd.concat([d, one_hot], axis=1)\n",
    "    #drop gender column\n",
    "    d.drop('gender', axis=1, inplace=True)\n",
    "    # replace the nonfloats/itns with ints \n",
    "    d.replace({'> 89': 100}, inplace = True)\n",
    "    d = d.drop_duplicates(subset=['patientunitstayid'], keep='first')\n",
    "    d = d.set_index('patientunitstayid')\n",
    "    d['cellattributevalue'] = 0\n",
    "    \n",
    "    #copy another instence on the next part of the dataset\n",
    "    d2 = df[['cellattributevalue', 'celllabel', 'offset', 'patientunitstayid']].copy()\n",
    "    d2.dropna(inplace=True)\n",
    "    #replace all nonfloat values with integers based off of numerics\n",
    "    d2.replace({'< 2 seconds': 0}, inplace = True)\n",
    "    d2.replace({'> 2 seconds': 1}, inplace = True)\n",
    "    d2.replace({'normal': 2}, inplace = True)\n",
    "    d2.replace({'hands': 3}, inplace = True)\n",
    "    d2.replace({'feet': 4}, inplace = True)\n",
    "    #index the patient ids with the cell atttributes to generate values in the finalized dataset\n",
    "    for idx, row in d2.iterrows():\n",
    "        id = row['patientunitstayid']\n",
    "        if id in d.index and pd.isna(d.at[id, 'cellattributevalue']):\n",
    "            d.at[id, 'cellattributevalue'] = row['cellattributevalue']\n",
    "    #generate new columns         \n",
    "    columns = ['pH', 'glucose']\n",
    "    d[columns] = None\n",
    "    \n",
    "    d3 = df[['labname','labresult','offset','patientunitstayid']].copy()\n",
    "    d3.dropna(inplace=True)\n",
    "    #index the patient ids with the cell atttributes to generate values in the finalized dataset\n",
    "    for i, row in d3.iterrows():\n",
    "        id = row['patientunitstayid']\n",
    "        labname = row['labname']\n",
    "        labresult = row['labresult']\n",
    "        if id in d.index:\n",
    "            if pd.isna(d.loc[id, labname]):\n",
    "                d.loc[id, labname] = labresult\n",
    "            else:\n",
    "                d.loc[id, labname] = min(d.loc[id, labname], labresult)\n",
    "                \n",
    "    #generate new columns             \n",
    "    columns = ['GCS Total', 'Heart Rate', 'Non-Invasive BP Diastolic', 'Non-Invasive BP Mean', 'Non-Invasive BP Systolic', 'Invasive BP Diastolic', 'Invasive BP Mean', 'Invasive BP Systolic', 'Respiratory Rate', 'O2 Saturation']\n",
    "    d[columns] = None\n",
    "    #copy another instence on the last part of the dataset\n",
    "    d4 = df[['nursingchartcelltypevalname','nursingchartvalue','offset','patientunitstayid']].copy()\n",
    "    \n",
    "    d4.dropna(inplace=True)\n",
    "    #index the patient ids with the cell atttributes to generate values in the finalized dataset\n",
    "    for i, row in d4.iterrows():\n",
    "        id = row['patientunitstayid']\n",
    "        if id in d.index:\n",
    "            current_value = d.loc[id, row['nursingchartcelltypevalname']]\n",
    "            new_value = row['nursingchartvalue']\n",
    "            if current_value is None or current_value > new_value:\n",
    "                d.loc[id, row['nursingchartcelltypevalname']] = new_value\n",
    "    #convert all types to floats     \n",
    "    d = d.astype(float)\n",
    "    #get all nans to be imputed with the mean datasets for the rows\n",
    "    d = d.fillna(d.mean())\n",
    "    finalized = d\n",
    "    return finalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8585328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish file paths\n",
    "x_train_file_path = 'train_x.csv/train_x.csv'\n",
    "x_test_file_path = 'test_x.csv/test_x.csv'\n",
    "y_train_file_path = 'train_y.csv'     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e5dc379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the respective file paths to data frames\n",
    "train_y = read_file(y_train_file_path)\n",
    "train_x = read_file(x_train_file_path)\n",
    "test_x = read_file(x_test_file_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eec13c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the dataset to make sure it remains a dataframe\n",
    "type(train_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609613c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexd\\AppData\\Local\\Temp\\ipykernel_32384\\2127944215.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['nursingchartvalue'] = pd.to_numeric(df['nursingchartvalue'], errors='coerce').astype(float)\n"
     ]
    }
   ],
   "source": [
    "#process the data accordingly \n",
    "train_x = process_data(train_x)\n",
    "test_x = process_data(test_x)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d44e98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show the dataset to make sure it all matches the correct format\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GradientBoostingRegressor with the specified hyperparameters\n",
    "gb = GradientBoostingRegressor(n_estimators=600,\n",
    "                                learning_rate=0.01,\n",
    "                                max_depth=2,\n",
    "                                min_samples_leaf=4,\n",
    "                                min_samples_split=2,\n",
    "                                subsample=0.5,\n",
    "                                random_state=42)\n",
    "\n",
    "# Fit the GradientBoostingRegressor to the training data\n",
    "gb.fit(train_x, train_y['hospitaldischargestatus'])\n",
    "\n",
    "# Use the trained model to predict the target variable for the test data\n",
    "y_pred = gb.predict(test_x)\n",
    "\n",
    "# Create a new DataFrame containing the patientunitstayid column from the test data\n",
    "done = test_x.filter(['patientunitstayid'])\n",
    "\n",
    "# Add the predicted hospitaldischargestatus values to the done DataFrame\n",
    "done['hospitaldischargestatus'] = y_pred\n",
    "\n",
    "# Save the done DataFrame to a CSV file\n",
    "done.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6fa28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the done dataframe for results\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02149809",
   "metadata": {},
   "source": [
    "Below is code imported from chatgpt to optimize hyperparams for GradientBoostingRegressor as this is the only ML model this project is using for simplicity purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f35588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "def optimize_hyperparams():\n",
    "    # Load the Boston housing dataset\n",
    "    X = train_x \n",
    "    y = train_y['hospitaldischargestatus']\n",
    "\n",
    "    # Define the hyperparameters to tune\n",
    "    hyperparams = {\n",
    "        'n_estimators': [400,500,600,700],\n",
    "        'learning_rate': [0.1, 0.01, 0.001],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'min_samples_split': [2],\n",
    "        'min_samples_leaf': [4],\n",
    "        'subsample': [0.25,0.5,0.75],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "\n",
    "    # Define the model\n",
    "    model = GradientBoostingRegressor()\n",
    "\n",
    "    # Perform grid search to find the best hyperparameters\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        hyperparams,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        cv=5\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Print the best hyperparameters and score\n",
    "    print('Best hyperparameters:', grid_search.best_params_)\n",
    "    print('Best score:', -1 * grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674a0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
